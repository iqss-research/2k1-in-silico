tab,type,Name,content
Intro,intro,Intro,"<p>Mastering statistical concepts requires repeated practice, but learning to code in R often diverts attention from the statistics itself. 2K1 simplifies this process, letting students focus on the material without needing coding skills. After lectures and readings, students can use 2K1 to generate data, explore how different choices affect outcomes, estimate models based on the data, and calculate key measures of interest. This approach allows for a deeper understanding of statistics in real-world contexts while keeping both the details and the big picture in view.</p>"
DGP,intro,DGPs and Probability,"<p><span style=\'color:#999\'>Use this tab first.</span></p><p>On this tab, you can use the <b>Probability Model</b> to set up a <b>Data Generating Process</b>, change its parameters, and see how it reacts. Using this tab will help you develop an intuition for probability distributions, and how they can represent uncertain reality.</p><p>This tab provides a peek behind the curtains into how all the data we might want to use comes into being. In the real world, this isn’t possible - usually, we find or collect a set of data, like the number of airstrikes in a conflict or a record of politicians’ votes in Congress, and start from there. It’s really important, though, to try to understand why the distribution of airstrikes (or congressional votes) looks the way it does (which we discuss in the inference tab!). While in real life we usually can’t know for sure how our data comes to look as it does, this tab is a world where we are in full control. </p><p> <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=6C7yRBfh2ok\'>This lecture video</a> gives an in-depth overview of probability concepts.</p><div class=""embed-responsive embed-responsive-16by9""><iframe class=""embed-responsive-item"" width=""560"" height=""315"" src=""https://www.youtube.com/embed/6C7yRBfh2ok"" title=""YouTube video player"" frameborder=""0"" allowfullscreen></iframe></div>"
MLE,intro,Likelihood Inference,"<p>This tab will present you with data generated in the first tab. Pretending you don\'t know where it came from, you can walk through the process of guessing the DGP given the data.</p><p>Unlike the DGP tab, which gives you the chance to go behind the scenes and create datasets, this is the tab that mirrors what we usually do with data in the real world: we have some values, and we want to figure out what process most likely created them: performing inference. A process we can’t see is doing the steps in the DGP tab to generate some data points that we do get to see, and we are trying to backtrace and figure out what that generation process is.  </p><p>Minutes 0-22 of <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=P79af1fkUsk\'>this video</a> describe the problem of inference.</p><p><a id=""lldRega"">Click here</a> to see how this relates to inference with linear regression.</p>"
Sim,intro,Simulation,"<p>Simulation is a tool for using inferences to gain broader and more useful knowledge and to present results in an easily understandable way.</p><p> In the QOI tab, you can mimic using the hard-earned results of your inferences to estimate values that you actually care about - this is often a key goal in statistics. From your set of real-world data (and remember, in the real world we cannot see the DGP that creates this data, though 2k1 lets us act like we can), you make an educated choice about what the DGP is: what type of model is most likely to have generated the dataset you have received. Then, you can use this model and the real-world data to compute quantities of interest - what are your predicted values, or expected values, based on the data you have and how you think it was formed? </p><p><a target=\'_blank\' href=\'https://www.youtube.com/watch?v=sTXVNbe8fto\'>This video</a> describes how to simulate from your results, and what it can get you.</p>"
MLE,intro,Likelihood Inference (Disabled),"<p><b>Use the DGP tab to create some data and unlock this tab.</b></p><p style=""color:#999;"">This tab will present you with data generated in the first tab. Pretending you don\'t know where it came from, you can walk through the process of guessing the DGP given the data.</p><p>Unlike the DGP tab, which gives you the chance to go behind the scenes and create datasets, this is the tab that mirrors what we usually do with data in the real world: we have some values, and we want to figure out what process most likely created them: performing inference. A process we can’t see is doing the steps in the DGP tab to generate some data points that we do get to see, and we are trying to backtrace and figure out what that generation process is.  </p><p style=\'color:#999\'>Minutes 0-22 of <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=P79af1fkUsk\'>this video</a> describe the problem of inference.</p><p style=\'color:#999\'><a id=""lldRega"">Click here</a> to see how this relates to inference with linear regression.</p>"
Sim,intro,Simulation (Disabled),"<p><b>Generate estimates with a Model before using Simulation.</b></p><p style=\'color:#999\'>Simulation is a tool for using inferences to gain broader and more useful knowledge, and present results in an easily understandable way. </p><p>In the QOI tab, you can mimic using the hard-earned results of your inferences to estimate values that you actually care about - this is often a key goal in statistics. From your set of real-world data (and remember, in the real world we cannot see the DGP that creates this data, though 2k1 lets us act like we can), you make an educated choice about what the DGP is: what type of model is most likely to have generated the dataset you have received. Then, you can use this model and the real-world data to compute quantities of interest - what are your predicted values, or expected values, based on the data you have and how you think it was formed? </p><p><a target=\'_blank\' href=\'https://www.youtube.com/watch?v=sTXVNbe8fto\'>This video</a> describes how to simulate from your results, and what it can get you.</p>"
DGP,intro,DGP Choice,"<p>Choose a family of <b>Data Generating Processes</b>. Each family consists of many members who share a probability model, but have different values of parameters. For example, if you are interested in modeling: <ul> <li>Vote choice, dyadic state interactions, state failure, or other dichotomous variables, you could select a <b> Bernoulli distribution </b> </li> <li>Time between wars, unemployment spells, years you will be stuck in grad school, or other times between independent events, you could select an <b> Exponential distribution </b> </li> <li>Wealth distributions, income, population, crime, budgets, or other positive and right skewed variables, you could select the <b> Log Normal distribution </b> </li> <li>The number of patents awarded to a firm, presidential vetoes each year, violent acts, or other event counts of independent events, you can use a <b> Poisson distribution </b> </li> <li>The number of publications by new professors, political kidnappings, or other event counts that are not independent, you can use a <b> Negative Binomial distribution </b>  </li> <li>Ordered scale responses that are related to a latent variable, you can use the <b> Ordered Logit or Probit distributions </b> </li> </ul> </p>"
DGP,intro,Probability Model,"<p>This is the Probability Model of this family of DGPs, describing how parameters become data.</p><ul style = ""padding-left:10px""> <li>The first part is a <b>Probability Density Function</b>, which turns parameters (Greek letters <span class=""math inline"">\\(\\beta, \\sigma, \\mu \\) etc.</span>) and covariates (<span class=""math inline"">\\(X\\)</span>) into outcomes (<span class=""math inline"">\\(Y\\)</span>)</li><li>The PDF represents the stochastic component of a <a target=\'_blank\' href=\'https://youtu.be/qbxNf4iqJPo?t=143\'><b>Statistical Model</b></a>. It also has a <b>systematic component</b> describing how parameters are set</li><li>The last part is a crucial <b>independence assumption</b> which lets us randomly generate outcomes one at a time (<span class=""math inline"">\\(\\perp \\!\\!\\! \\perp\\)</span> means \"is independent from\")</li></ul><p>The Probability Model is described in depth in <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=6C7yRBfh2ok\'>this video</a>.<iframe width=""560"" height=""315"" src=\'https://www.youtube.com/embed/6C7yRBfh2ok\' title=""YouTube video player"" frameborder=""0"" allowfullscreen></iframe></p>"
DGP,intro,Observation Choice,Decide how much data you want to generate.
DGP,intro,Covariates,"<p>The outcome variable of this DGP - <span class=""math inline"">\\(Y\\)</span> - depends on its <b>covariates</b>, <span class=""math inline"">\\(X\\)</span>. These are random variables that, with the parameters, combine into <span class=""math inline"">\\(Y\\)</span> as described by the Probability Model (see <a target=\'_blank\' href=\'https://youtu.be/qbxNf4iqJPo?t=281\'>this video</a> for more detail). The covariates are fixed: we\'ve generated them beforehand, according to various DGPs. You can go <a target=\'_blank\' href=\'https://docs.google.com/spreadsheets/d/1iLBqVaGuLxXyPF4LfuggeGfTZC2roSSaF-cnqSD7TEU/edit?usp=sharing\'>here</a> to see the covariate choices. </p><p>Use the buttons to add or remove covariates.</p>"
DGP,intro,Parameters,"These sliders let you choose parameters. Depending on the DGP, these will directly control the shape of the distribution that you see in the <i>Analytical Plot</i>, or combine with the parameters first (as described in the Probability Model)."
DGP,intro,Analytical Plot,"<p>This <b>density</b> or <b>mass</b> plot represents your DGP graphically. It tells you how probable it is for the outcome to take on particular ranges of values, based on your parameter and covariate choices. It is a <i>marginal</i> plot. Sometimes there are multiple PDFs, one for each value  of X. This combines all of them.</p><p> This plot comes from the Probability Model - it isn\'t randomly generated! But if you randomly generated more and more data, the histogram of that data would look more and more like this. </p>"
DGP,intro,Ordinal Plot,The relative probability of each of the values as the chosen covariate changes.
DGP,intro,Parameter Histogram,"<p>This plot describes the intermediate parameter, which is generated based on your parameters combined with the covariate. For the Normal (X) family of DGPs, this is a histogram of <span class=""math inline"">\\(\\mu\\)</span>; for the Bernoulli (Logit, X) family, it is a histogram of <span class=""math inline"">\\(\\pi\\)<span></p>"
DGP,intro,Functional Form,"This is how a particular covariate turns into a parameter, holding other covariates fixed at their means. For a Normal (X) DGP, this will be a line with slope <span class=""math inline"">\\(\\beta_i\\)</span> and intercept <span class=""math inline"">\\(\\beta_0\\)</span>. For a Bernoulli (Logit), this will be a plot of the logistic function, logit(<span class=""math inline"">\\(X\\beta_i\\)</span>)."
DGP,intro,Randomly Generated Data,"<p>Here are the <span class=""math inline"">\\(Y\\)</span> values you\'ve generated from the DGP. Try changing parameters, and see how it changes.</p> <p>On the <i>Model</i> tab, we\'ll treat this data as if we don\'t know where it came from, and use it to learn about inference.</p><p>By the way, you may run into the silly longstanding argument over whether the word \"data\" is plural (\"these data are...\") or singular (\"the data is...\"); this utterly doesn\'t matter, but a better way to think about this is that \"data\" (like \"rice\") is a collective noun (and so \"The data is...\").</p>"
MLE,intro,Data for Inference,Now we are going to treat our data as if we didn\'t know the DGP and use inference to try and guess it.
MLE,intro,Model Selection,"<p>You can look at our data, or consult theory, and select a model that\'s our best guess of the true DGP. Of course, in this app, you know the DGP (look at the top bar, if you\'ve forgotten!). But it can be interesting to try changing the model and see how the prediction process works when the model is definitely wrong. As a reminder, if you are interested in modeling: <ul> <li>Vote choice, dyadic state interactions, state failure, or other dichotomous variables, you could select a <b> Bernoulli distribution </b> </li> <li>Time between wars, unemployment spells, years you will be stuck in grad school, or other times between independent events, you could select an <b> Exponential distribution </b> </li> <li>Wealth distributions, income, population, crime, budgets, or other positive and right skewed variables, you could select the <b> Log Normal distribution </b> </li> <li>The number of patents awarded to a firm, presidential vetoes each year, violent acts, or other event counts of independent events, you can use a <b> Poisson distribution </b> </li> <li>The number of publications by new professors, political kidnappings, or other event counts that are not independent, you can use a <b> Negative Binomial distribution </b>  </li> <li>Ordered scale responses that are related to a latent variable, you can use the <b> Ordered Logit or Probit distributions </b> </li> </ul> <p>"
MLE,intro,Hypothesize a Covariate,"<p>Hypothesize a covariate. A researcher might hypothesize that some observed data - income - is attributable to one or more covariates - education, parents\' incomes, etc.  The covariates are generated randomly beforehand, according to various DGPs. You can go <a target=\'_blank\' href=\'https://iqss-research.github.io/2k1-in-silico\'>here</a> to see the covariate choices. </p><p>Use the buttons to add or remove covariates.</p>"
MLE,intro,Statistical Model,"<p>This is the statistical model, describing the family of models we chose. We\'re going to look at different parameter values - different members of this family - until we find the best fit.</p><p>If you\'re used to linear regression notation,  <a target=\'_blank\' href=\'https://youtu.be/qbxNf4iqJPo?t=490\'>this comparison</a> might be useful.</p>"
MLE,intro,Guesstimate,"With this, you can approximate likelihood inference by hand. Try moving the sliders around until the green line (your DGP guess) matches the blue bars, as best as you can get. Hit the button to set the sliders to the maximum likelihood estimates."
MLE,intro,Guesstimate Plot,"The choice of model determines how you\'re going to be able to move the green line. If you\'ve chosen the wrong model, this could be a diagnostic. Suppose you choose a Stylized Normal to model Normally-distributed data. Then, the data might be more or less dispersed than you can capture with this plot. This sort of error is called <i>misspecification</i>."
MLE,intro,Likelihood,"Now let\'s formalize our guessing process. We want to know which member of our family of DGPs is most likely to have generated our data. To do that, we choose the potential parameter values that maximize a likelihood function (specifically, the log of the likelihood function, for computational reasons). This is the function to maximize, where k(y) is a positive constant that is an unknown function of the data (see <a target=\'_blank\' href=\'https://iqss-research.github.io/2k1-in-silico\'>docs</a>).<br />For a detailed discussion of likelihood inference, including where these functions come from, see <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=hIGVciyWUn0\'>this video</a>."
MLE,intro,Likelihood Plot,"<b>Maximum Likelihood Estimation</b> - like the name suggests - involves picking the parameter value that maximizes the log-likelihood function. The highest point on this plot tells us which parameters are most likely. If the plot is very flat near its peak, that means other parameter values are almost as likely, so we\'re not as sure of our estimate. If the plot is very pointed, that indicates more certainty. This is captured in the standard error, which is derived from the curvature of the log-likelihood at its peak."
MLE,intro,Functional Form (Model),"A plot of the functional form of our hypothesized DGP, with all the other parameters held at their MLEs."
MLE,intro,Estimates,"The final output of our maximum likelihood estimation. The first part is a point estimate: our best guess for the real &beta;, given our assumed model. The second part is an estimate of uncertainty, reflecting how sure we are about that guess - were other values of &beta; nearly as likely?"
Sim,intro,Estimates (Sim),"Here\'s our starting point: the point estimates you made before, with an estimated uncertainty around them. "
Sim,intro,Quantity of Interest,"<p>Use this dropdown to choose a quantity of interest for the top right graph. Predicted Values will show the range of possible values for Y given the chosen parameters, and Probability Y \> 1 will show the probability that these Predicted Values are greater than 1. Expected Values will show the expectation for Y, which differs from the Predicted Values by producing 100 possible values and averaging over them for each single Predicted Value draw. Sim. Parameter, where available, displays the specified parameter\'s predicted values, when simulated from the selected model.</p>"
Sim,intro,Chosen Covariate,"This slider lets you pick X. Before, we were using covariates to estimate our model. Now we\'ve estimated the model. Maybe I estimated the relationship of Democratic vote share to advertising. Now I can ask\: Given a certain level of advertising expenditure, how much vote share can the Democrats expect to gain - and how certain can I be about that?"
Sim,intro,Estimation and Fundamental Uncertainty,"<p>There are two kinds of uncertainty to represent when simulating. The first is <i>estimation uncertainty</i>. We\'re only observing a fraction of a population. What can we tell from a limited sample?</p><p>The second kind is <i>Fundamental Uncertainty</i>. Even if we know everything about how advertising expenditure affects voting, there are hundreds of other factors that also determine Democratic vote share - so estimates of vote share based on advertising expenditure are always uncertain. Of course, if I only want to estimate how much advertising spending affects vote share on average, I may not be worried about that.</p>"
Sim,intro,QOI Histogram,"Here\'s the distribution of the quantity of interest you picked. The histogram represents the results of 1,000 simulations. In this case, it represents predicted values that Y can take on given the X you picked, and the estimation and fundamental uncertainty."
Sim,intro,Functional Form (Simulation),"This plot shows us one perspective on our estimation uncertainty. Given different covariate values, the line shows us the expected value of parameters, and the band shows us the 80% confidence interval around the blue line. "
Reg,intro,Regression 1,"<p>You may already have learned the basics of probability and inference in a class based around linear regression. Regression is one of the most commonly used tools for inference (using what we know to find out about what we don't know). This app seeks to describe the foundations of regression and other tools with a broader approach: maximum likelihood estimation (MLE). Using MLE, you can understand many different tools, including linear regression: here's how.</p><p>In a linear regression you are trying to understand an outcome \(Y\), using a particular statistical model where $$Y = X\beta + \varepsilon$$ Here \(\beta\) is some coefficients, \(X\) is all your covariates, and \(\varepsilon\) is an 'error' term. This last part - the error term - represents the factors influencing \(Y\) that aren't in \(X\), and is assumed to have mean 0. This model specifies a family of DGPs with a parameter \( \beta \): you then figure out which values of \( \beta\) fit your data best. </p> <p>This simple plot describes the fitting process. The dots represent observations of \(Y\), and the line is your predictions \(\hat y\). By moving the line you are choosing a single parameter to best fit your data.</p>"
Reg,intro,Regression 2,"<p>Frequently, in order to interpret or extend regression findings, you might take a more <i>model-based</i> approach, making assumptions about the distribution of the DGP. In a regression, that means you place a restriction on the error \(\varepsilon\) by assuming it is not only centered on zero, but normally distributed with variance \(\sigma^2\). Then, you are trying to select one of a family of normal DGPs that corresponds best to your data. This is the exact same process you'll see if you use a Normal-family DGP and model.</p><p>It's tempting to say that making this sort of assumption is just bad. After all, most research subjects are complicated. Assuming they follows a Normal distribution is just wrong! But social scientists aren't trying to <i>represent</i> the world perfectly. We use models to <i>abstract</i>: representing what's important and discarding what's not. So don't ask if the model is wrong - every model is wrong! Ask if it's useful. In the Quantities of Interest tab of this app, you'll see how useful these assumptions can be.</p><p>The chart and slider below replicate this model-fitting process. The chart and slider below replicate this model-fitting process. Think of the blue histogram as the data (it is the marginal distribution of Y) and the green line as linear-normal regression fit to the data. You're trying to get the two to match up.</p> "
Reg,intro,Regression 3,"There's no reason to restrict ourselves to linear-normal models.. For example, you might be interested in a binary outcome - a decision to approve or deny a loan, or support or oppose a ballot initiative. Then you could model \(Y\) as \(\text{Bernoulli}[\text{logit}(X\beta)]\). In the plot below, you can move the slider up and down until your predicted values fit what's observed."
