tab,type,Name,content
Intro,intro,Intro,"<h2>2K1-in-Silico</h2>
<p><a target=""_blank"" href=""https://GaryKing.org"">Gary King</a> and <a target=""_blank"" href=""https://ZagrebMukerjee.com"">Zagreb Mukerjee</a>
<p>So you want to be a social scientist, and the first course they make you take is <em>statistics</em>!?  Well, statistics is about inference -- using facts you know to learn about facts you don't know -- and so perhaps you can convince yourself that it is fundamental to empirical research (really, it is!). OK, but then your social science statistics instructor makes you learn a <em>programming language</em>!?  Gosh, spending time fixing an obscure bug on line 168 of your R code, while you are supposed to be grasping deep concepts in statistical inference, feels like a massive distraction.  Learning while doing, controlling inputs and watching how outputs change, is certainly more productive than merely consulting a static textbook but, until now, programming lessons wind up interrupting learning (not much different than if we made you take swimming lessons halfway through class) and well before you start to benefit.
</p>

<p>2K1-in-Silico implements two pedagogical innovations that our research shows will enable you to learn statistical inference faster and better.  First, we enable you to postpone programming lessons and still learn by doing, by giving you complete control over all inputs in a simple web interface with instant numerical and graphic results and feedback. (Learning programming, when you get to it, will be easier too after you understand inference.) Second, we provide extensive, automated in-context assistance if, when, and where you need it. Throughout, you will see little tooltips marked <b>i</b>, to click for more information (a tooltip will open automatically when its content is essential or likely to be missed). 
</p>

<p>2K1-in-Silico (presently) enables you to learn three concepts, each with its own tab at the top of the screen:</p>
<ul style = ""padding-left:25px;"">
<li><b>Data Generation Processes</b>, using the model of <em>probability</em>;</li>
<li><b>Likelihood</b>, an extremely widely used theory of statistical inference, one that underlies many other such theories; likelihood is almost the inverse of probability, where we observe the data and try to infer the data generation process; and</li>
<li><b>Simulation</b>, a technique that enables you (rather than some computer program) to control how statistical results are presented, so you can understand your work better and it is more impactful</li>
</ul>

<p>The app parallels some of the core, model-based content of <a target=""_blank"" href=""https://projects.iq.harvard.edu/gov2001/"">Gov 2001</a>, the first course in the Harvard Government Department's social science methods sequence (taught by Gary King). The course is open to all for credit (even those not at Harvard via the Harvard Extension School as Stat E-200). Some of you may already have taken a political science methodology, econometrics, or statistics class focused on regression - our approach covers the same concepts, but in a more general and fundamental way. <a id=""introRega"">Click here</a> to see how.</p>

<p>All the lectures, videos, and much other teaching materials, including this app, are available for other instructors and students to use in their courses as well from the course website, <a target=""_blank"" href=""https://projects.iq.harvard.edu/gov2001/"">j.mp/G2001</a>, many parts of which are linked to in the tooltips. (Thanks to generations of Gov2001 students for helping us improve the ideas behind this app.) <a target=""_blank"" href=""https://youtu.be/qs2uCuDL2OQ?t=2416"">This lecture video</a> gives an overview of the course.
</p>

<p>To learn more about 2K1-in-Silico, to send comments or suggestions, or to contribute to this open source package, see the <a target=""_blank""  href = ""https://github.com/iqss-research/2k1-in-silico"">app's Github repository</a>.</p>
"
DGP,intro,DGPs and Probability,"<p><span style=\'color:#999\'>Use this tab first.</span></p><p>On this tab, you can use the <b>Probability Model</b> to set up a <b>Data Generating Process</b>, change its parameters, and see how it reacts. Using this tab will help you develop an intuition for probability distributions, and how they can represent uncertain reality.</p><p> <a target=\'_blank\' href=\'https://www.youtube.com/watch?v=6C7yRBfh2ok\'>This lecture video</a> gives an in-depth overview of probability concepts.</p>"
MLE,intro,Likelihood Inference,"<p>This tab will present you with data generated in the first tab. Pretending you don\'t know where it came from, you can walk through the process of guessing the DGP given the data.</p><p>Minutes 0-22 of <a target=""_blank"" href=""https://www.youtube.com/watch?v=P79af1fkUsk"">this video</a> describe the problem of inference.</p><p><a id=""lldRega"">Click here</a> to see how this relates to inference with linear regression.</p>"
Sim,intro,Simulation,"<p>Simulation is a tool for using inferences to gain broader and more useful knowledge, and present results in an easily understandable way. <a target=""_blank"" href=""https://www.youtube.com/watch?v=sTXVNbe8fto"">This video</a> describes how to simulate from your results, and what it can get you.</p>"
MLE,intro,Likelihood Inference (Disabled),"<p><b>Use the DGP tab to create some data and unlock this tab.</b></p><p style=""color:#999;"">This tab will present you with data generated in the first tab. Pretending you don\'t know where it came from, you can walk through the process of guessing the DGP given the data.</p><p style=\'color:#999\'>Minutes 0-22 of <a target=""_blank"" href=""https://www.youtube.com/watch?v=P79af1fkUsk"">this video</a> describe the problem of inference.</p><p style=\'color:#999\'><a id=""lldRega"">Click here</a> to see how this relates to inference with linear regression.</p>"
Sim,intro,Simulation (Disabled),"<p><b>Generate estimates with a Model before using Simulation.</b></p><p style=\'color:#999\'>Simulation is a tool for using inferences to gain broader and more useful knowledge, and present results in an easily understandable way. <a target=""_blank"" href=""https://www.youtube.com/watch?v=sTXVNbe8fto"">This video</a> describes how to simulate from your results, and what it can get you.</p>"
DGP,intro,DGP Choice,"Choose a family of <b>Data Generating Processes</b>. Each family consists of many members who share a probability model, but have different values of parameters."
DGP,intro,Probability Model,"<p>This is the Probability Model of this family of DGPs, describing how parameters become data.</p><ul style = ""padding-left:10px""> <li>The first part is a <b>Probability Density Function</b>, which turns parameters(greek letters <span class=""math inline"">\\(\\beta, \\sigma, \\mu \\) etc.</span>) and covariates (<span class=""math inline"">\\(X\\)</span>) into outcomes (<span class=""math inline"">\\(Y\\)</span>)</li><li>The PDF represents the stochastic component of a <a target=""_blank"" href=""https://youtu.be/qbxNf4iqJPo?t=143""><b>Statistical Model</b></a>. It also has a <b>systematic component</b> describing how parameters are set.</li><li>The last part is a crucial <b>independence assumption</b> which lets us randomly generate outcomes one at a time (<span class=""math inline"">\\(\\perp \\!\\!\\! \\perp\\)</span> means ""is independent from"")</li></ul><p>The Probability Model is described in depth in <a target=""_blank"" href=""https://www.youtube.com/watch?v=6C7yRBfh2ok"">this video</a>.</p>"
DGP,intro,Observation Choice,Decide how much data you want to generate.
DGP,intro,Covariates,"<p>The outcome variable of this DGP - <span class=""math inline"">\\(Y\\)</span> - depends on its <b>covariates</b>, <span class=""math inline"">\\(X\\)</span>. These are random variables that, with the parameters, combine into <span class=""math inline"">\\(Y\\)</span> as described by the Probability Model (see <a target=""_blank"" href=""https://youtu.be/qbxNf4iqJPo?t=281"">this video</a> for more detail). The covariates are fixed: we\'ve generated them beforehand, according to various DGPs. You can go <a target=""_blank"" href=""https://docs.google.com/spreadsheets/d/1iLBqVaGuLxXyPF4LfuggeGfTZC2roSSaF-cnqSD7TEU/edit?usp=sharing"">here</a> to see the covariate choices. </p><p>Use the buttons to add or remove covariates.</p>"
DGP,intro,Parameters,"These sliders let you choose parameters. Depending on the DGP, these will directly control the shape of the distribution that you see in the <i>Analytical Plot</i>, or combine with the parameters first (as described in the Probability Model)."
DGP,intro,Analytical Plot,"<p>This <b>density</b> or <b>mass</b> plot represents your DGP graphically. It tells you how probable it is for the outcome to take on particular ranges of values, based on your parameter and covariate choices. It is a <i>marginal</i> plot. Sometimes there are multiple PDFs, one for each value  of X. This combines all of them.</p><p> This plot comes from the Probability Model - it isn\'t randomly generated! But if you randomly generated more and more data, the histogram of that data would look more and more like this. </p>"
DGP,intro,Ordinal Plot,The relative probability of each of the values as the chosen covariate changes.
DGP,intro,Parameter Histogram,"<p>This plot describes the intermediate parameter, which is generated based on your parameters combined with the covariate. For the Normal (X) family of DGPs, this is a histogram of <span class=""math inline"">\\(\\mu\\)</span>; for the Bernoulli (Logit, X) family, it is a histogram of <span class=""math inline"">\\(\\pi\\)<span></p>"
DGP,intro,Functional Form,"This is how a particular covariate turns into a parameter, holding other covariates fixed at their means. For a Normal (X) DGP, this will be a line with slope <span class=""math inline"">\\(\\beta_i\\)</span> and intercept <span class=""math inline"">\\(\\beta_0\\)</span>. For a Bernoulli (Logit), this will be a plot of the logistic function, logit(<span class=""math inline"">\\(X\\beta_i\\)</span>)."
DGP,intro,Randomly Generated Data,"<p>Here are the <span class=""math inline"">\\(Y\\)</span> values you\'ve generated from the DGP. Try changing parameters, and see how it changes.</p> <p>On the <i>Model</i> tab, we\'ll treat this data as if we don\'t know where it came from, and use it to learn about inference.</p><p>By the way, you may run into the silly longstanding argument over whether the word \""data\"" is plural (\""these data are...\"") or singular (\""the data is...\""); this utterly doesn\'t matter, but a better way to think about this is that \""data\"" (like \""rice\"") is a collective noun (and so \""The data is...\"").</p>"
MLE,intro,Data for Inference,"Now we are going to treat our data as if we didn\'t know the DGP, and use inference to try and guess it. "
MLE,intro,Model Selection,"You can look at our data, or consult theory, and select a model that\'s our best guess of the true DGP. Of course, in this app, you know the DGP (look at the top bar, if you\'ve forgotten!). But it can be interesting to try changing the model, and see how the prediction process works when the model is definitely wrong."
MLE,intro,Hypothesize a Covariate,"<p>Hypothesize a covariate. A researcher might hypothesize that some observed data - income - is attributable to one or more covariates - education, parents\' incomes, etc.  The covariates are generated randomly beforehand, according to various DGPs. You can go <a target=""_blank"" href=""https://projects.iq.harvard.edu/2k1-in-silico/x-values"">here</a> to see the covariate choices. </p><p>Use the buttons to add or remove covariates.</p>"
MLE,intro,Statistical Model,"<p>This is the statistical model, describing the family of models we chose. We\'re going to look at different parameter values - different members of this family - until we find the best fit.</p><p>If you\'re used to linear regression notation,  <a target=""_blank"" href=""https://youtu.be/qbxNf4iqJPo?t=490"">this comparison</a> might be useful.</p>"
MLE,intro,Guesstimate,"With this, you can approximate likelihood inference by hand. Try moving the sliders around until the green line (your DGP guess) matches the blue bars, as best as you can get. Hit the button to set the sliders to the maximum likelihood estimates."
MLE,intro,Guesstimate Plot,"The choice of model determines how you\'re going to be able to move the green line. If you\'ve chosen the wrong model, this could be a diagnostic. Suppose you choose a Stylized Normal to model Normally-distributed data. Then, the data might be more or less dispersed than you can capture with this plot. This sort of error is called <i>misspecification</i>."
MLE,intro,Likelihood,"Now let\'s formalize our guessing process. We want to know which member of our family of DGPs is most likely to have generated our data. To do that, we choose the potential parameter values that maximize a likelihood function (specifically, the log of the likelihood function, for computational reasons). This is the function to maximize. For a detailed discussion of likelihood inference, including where these functions come from, see <a target=""_blank"" href=""https://www.youtube.com/watch?v=hIGVciyWUn0"">this video</a>."
MLE,intro,Likelihood Plot,"<b>Maximum Likelihood Estimation</b> - like the name suggests - involves picking the parameter value that maximizes the log-likelihood function. The highest point on this plot tells us which parameters are most likely. If the plot is very flat near its peak, that means other parameter values are almost as likely,so we\'re not as sure of our estimate. If the plot is very pointed, that indicates more certainty. This is captured in the standard error, which is derived from the curvature of the log-likelihood at its peak."
MLE,intro,Functional Form (Model),"A plot of the functional form of our hypothesized DGP, with all the other parameters held at their MLEs."
MLE,intro,Estimates,"The final output of our maximum likelihood estimation. The first part is a point estimate: our best guess for the real &beta;, given our assumed model. The second part is an estimate of uncertainty, reflecting how sure we are about that guess - were other values of &beta; nearly as likely?"
Sim,intro,Estimates (Sim),"Here\'s our starting point: the point estimates you made before, with an estimated uncertainty around them. "
Sim,intro,Quantity of Interest,"Use this dropdown to choose a quantity of interest. For example, maybe I want to choose a value of X, and see what range of values of Y are possible; or maybe I want to see the probability that Y is greater than .5."
Sim,intro,Chosen Covariate,"This slider lets you pick X. Before, we were using covariates to estimate our model. Now we\'ve estimated the model. Maybe I estimated the relationship of Democratic vote share to advertising. Now I can ask, ""Given a certain level of advertising expenditure, how much vote share can the Democrats expect to gain - and how certain can I be about that?"""
Sim,intro,Estimation and Fundamental Uncertainty,"<p>There are two kinds of uncertainty to represent when simulating. The first is <i>estimation uncertainty</i>. We\'re only observing a fraction of a population. What can we tell from a limited sample?</p><p>The second kind is <i>Fundamental Uncertainty</i>. Even if we know everything about how advertising expenditure affects voting, there are hundreds of other factors that also determine Democratic vote share - so estimates of vote share based on advertising expenditure are always uncertain. Of course, if I only want to estimate how much advertising spending affects vote share on average, I may not be worried about that.</p>"
Sim,intro,QOI Histogram,"Here\'s the distribution of the quantity of interest you picked. The histogram represents the results of 1,000 simulations. In this case, it represents predicted values that Y can take on given the X you picked, and the estimation and fundamental uncertainty."
Sim,intro,Functional Form (Simulation),"This plot shows us one perspective on our estimation uncertainty. Given different covariate values, the line shows us the expected value of parameters, and the band shows us the 80% confidence interval around the blue line. "
Reg,intro,Regression 1,"<p>You may already have learned the basics of probability and inference in a class based around linear regression. Regression is one of the most commonly used tools for inference (using what we know to find out about what we don't know). This app seeks to describe the foundations of regression and other tools with a broader approach: maximum likelihood estimation (MLE). Using MLE, you can understand many different tools, including linear regression: here's how.</p><p>In a linear regression you are trying to understand an outcome \(Y\), using a particular statistical model where $$Y = X\beta + \varepsilon$$ Here \(\beta\) is some coefficients, \(X\) is all your covariates, and \(\varepsilon\) is an 'error' term. This last part - the error term - represents the factors influencing \(Y\) that aren't in \(X\), and is assumed to have mean 0. This model specifies a family of DGPs with a parameter \( \beta \): you then figure out which values of \( \beta\) fit your data best. </p> <p>This simple plot describes the fitting process. The dots represent observations of \(Y\), and the line is your predictions \(\hat y\). By moving the line you are choosing a single parameter to best fit your data.</p>"
Reg,intro,Regression 2,"<p>Frequently, in order to interpret or extend regression findings, you might take a more <i>model-based</i> approach, making assumptions about the distribution of the DGP. In a regression, that means you place a restriction on the error \(\varepsilon\) by assuming it is not only centered on zero, but normally distributed with variance \(\sigma^2\). Then, you are trying to select one of a family of normal DGPs that corresponds best to your data. This is the exact same process you'll see if you use a Normal-family DGP and model.</p><p>It's tempting to say that making this sort of assumption is just bad. After all, research subject is probably a complicated social phenomenon. Assuming it follows a Normal distribution is just wrong! But social scientists aren't trying to <i>represent</i> the world perfectly. We use models to <i>abstract</i>: representing what's important and discarding what's not. So don't ask if the model is wrong - every model is wrong! Ask if it's useful. In the Quantities of Interest tab of this app, you'll see how useful these assumptions can be.</p><p>The chart and slider below replicate this model-fitting process. Think of the blue bar as the realized distribution of \(y - \bar y\), and the green line as \(\hat y - y\). You're trying to get the two to match up.</p> "
Reg,intro,Regression 3,"The likelihood inference approach described in this app can also describe a broader set of potential DGPs. For example, you might be interested in a binary outcome - a decision to approve or deny a loan, or support or oppose a ballot initiative. Then you could model \(Y\) as \(\text{Bernoulli}[\text{logit}(X\beta)]\). In the plot below, you can move the slider up and down until your predicted values fit what's observed."
